{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUTlNO1gdZI4"
      },
      "source": [
        "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUUekT1hdZI8"
      },
      "source": [
        "# Képosztályozás az MNIST adathalmazzal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSxLw-1NdZI9"
      },
      "source": [
        "Ebben a szakaszban a mélytanulás \"Hello World\"-jét fogjuk elvégezni: egy mélytanulási modellt képzünk ki a kézzel írt számjegyek helyes osztályozására."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikd_OIWCdZI9"
      },
      "source": [
        "* Értsd meg, hogy a mélytanulás hogyan képes megoldani olyan problémákat, amelyeket a hagyományos programozási módszerek nem tudnak megoldani.\n",
        "* Ismerje meg az [MNSIT kézzel írt számjegyek adathalmazát](http://yann.lecun.com/exdb/mnist/)\n",
        "* A [Keras API](https://keras.io/) használata az MNIST adathalmaz betöltéséhez és a képzéshez való előkészítéséhez\n",
        "* Hozzon létre egy egyszerű neurális hálózatot a képosztályozás elvégzéséhez\n",
        "* A neurális hálózat képzése az előkészített MNIST-adatkészlet segítségével\n",
        "* Figyelje meg a betanított neurális hálózat teljesítményét."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SygRxpD3dZI-"
      },
      "source": [
        "## A probléma: Képosztályozás"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOKMsel8dZI-"
      },
      "source": [
        "A hagyományos programozás során a programozó képes szabályokat és feltételeket megfogalmazni a kódjában, amelyeket a programja a megfelelő módon történő cselekvéshez használhat. Ez a megközelítés továbbra is kivételesen jól működik a legkülönbözőbb problémák esetében.\n",
        "\n",
        "A képosztályozás, amely arra kéri a programot, hogy helyesen soroljon be egy olyan képet a megfelelő osztályba, amelyet még soha nem látott, a hagyományos programozási technikákkal szinte lehetetlen megoldani. Hogyan tudná egy programozó meghatározni azokat a szabályokat és feltételeket, amelyekkel helyesen osztályozhatná a képek óriási választékát, különösen olyan képek figyelembevételével, amelyeket még soha nem látott?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcb6GkuldZI-"
      },
      "source": [
        "## A megoldás: Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu1mftdxdZI_"
      },
      "source": [
        "A mélytanulás a próbálgatással történő mintafelismerésben jeleskedik. Ha egy mély neurális hálózatot elegendő adattal betanítunk, és a hálózatnak a képzésen keresztül visszajelzést adunk a teljesítményéről, a hálózat hatalmas mennyiségű iterációval képes azonosítani a saját feltételrendszerét, amely alapján a megfelelő módon tud cselekedni."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjllhGHbdZI_"
      },
      "source": [
        "## Az MNIST adathalmaz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J__4iQTedZJA"
      },
      "source": [
        "A mélytanulás történetében jelentős előrelépés volt a [MNSIT adathalmaz] (http://yann.lecun.com/exdb/mnist/) pontos képosztályozása, amely egy 70 000 szürkeárnyalatos képet tartalmazó gyűjtemény kézzel írt számjegyekről 0-tól 9-ig. Míg ma a probléma triviálisnak számít, a képosztályozás elvégzése az MNIST-tel egyfajta \"Hello World\" lett a mélytanulás számára."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj7m-AmkdZJA"
      },
      "source": [
        "Here are 40 of the images included in the MNIST dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eZeasQgdZJA"
      },
      "source": [
        "<img src=\"./images/mnist1.png\" style=\"width: 600px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otLz_TuQdZJA"
      },
      "source": [
        "## Tanítési és validálási adatok és címkék"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV7lHfRbdZJB"
      },
      "source": [
        "Amikor képekkel dolgozunk a mélytanuláshoz, szükségünk van magukra a képekre, amelyeket általában \"X\"-ként jelölünk, valamint a képek helyes [címkékre] (https://developers.google.com/machine-learning/glossary#label), amelyeket általában \"Y\"-ként jelölünk. Továbbá, szükségünk van `X` és `Y` értékekre a modell *kiképzéséhez*, majd egy külön `X` és `Y` értékkészletre a modell teljesítményének *érvényesítéséhez* a modell kiképzése után. Ezért az MNIST-adatkészlethez 4 szegmensre van szükségünk:\n",
        "\n",
        "1. `x_train`: A neurális hálózat képzéséhez használt képek\n",
        "2. `y_train`: Az \"x_train\" képek helyes címkézése, a modell előrejelzéseinek értékelésére szolgál a képzés során.\n",
        "3. `x_valid`: A modell teljesítményének validálására elkülönített képek a modell betanítása után.\n",
        "4. `y_valid`: Az \"x_valid\" képek helyes címkék, amelyek a modell előrejelzéseinek értékelésére szolgálnak a modell betanítása után.\n",
        "\n",
        "Az adatok elemzésre való előkészítésének folyamatát [Data Engineering]-nek nevezzük (https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7). Ha többet szeretne megtudni a képzési adatok és a validációs adatok (valamint a tesztadatok) közötti különbségekről, olvassa el Jason Brownlee [ezt a cikket](https://machinelearningmastery.com/difference-test-validation-datasets/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhwhOiQTdZJB"
      },
      "source": [
        "## Az adatok betöltése a memóriába (Keras segítségével)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FkfjVvedZJB"
      },
      "source": [
        "Számos [mélytanulási keretrendszer](https://developer.nvidia.com/deep-learning-frameworks) létezik, mindegyiknek megvannak a maga érdemei. Ebben a workshopban a [Tensorflow 2](https://www.tensorflow.org/tutorials/quickstart/beginner), és konkrétan a [Keras API](https://keras.io/) segítségével fogunk dolgozni. A Keras számos hasznos beépített függvényt tartalmaz, amelyeket a számítógépes látás feladataihoz terveztek. Az [olvashatósága](https://blog.pragmaticengineer.com/readable-code/) és hatékonysága miatt professzionális környezetben is legitim választás a mélytanuláshoz, bár nem egyedül áll ebben a tekintetben, és érdemes többféle keretrendszert is megvizsgálni, amikor egy mélytanulási projektbe kezdünk.\n",
        "\n",
        "A Keras által biztosított számos hasznos funkció egyike a számos segédmódszert tartalmazó modulok [számos gyakori adatkészlethez](https://www.tensorflow.org/api_docs/python/tf/keras/datasets), köztük az MNIST-hez.\n",
        "\n",
        "Kezdjük a Keras adatkészlet moduljának betöltésével az MNIST-hez:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rbX192SdZJC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KzeNyvLdZJD"
      },
      "source": [
        "Az `mnist` modullal egyszerűen betölthetjük az MNIST adatokat, amelyek már képekre és címkékre vannak felosztva mind a képzéshez, mind a validáláshoz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X-qdqu8dZJD",
        "outputId": "d23707d9-b1e6-4487-c915-cd65024166bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# az adatok, felosztva a training és a validáló készletekre\n",
        "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6_I0NT2dZJD"
      },
      "source": [
        "## Az MNIST adatok feltárása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmHr9iNfdZJE"
      },
      "source": [
        "Fentebb megállapítottuk, hogy az MNIST-adatkészlet 70 000 szürkeárnyalatos képet tartalmazott kézzel írt számjegyekről. A következő cellákat végrehajtva láthatjuk, hogy a Keras ezekből a képekből 60 000-et partícionált a képzéshez, és 10 000-et a validáláshoz (a képzés után), valamint azt is, hogy minden egyes kép maga egy 2D-s tömb, 28x28-as méretekkel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUqoYepcdZJE",
        "outputId": "3496eff7-a339-4ace-cdfd-ba5d9d4984cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK2MnLWMdZJE",
        "outputId": "21897845-f28e-467b-ae6d-7ef0c33c1cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5P_hU2wdZJE"
      },
      "source": [
        "Továbbá láthatjuk, hogy ezek a 28x28-as képek 0 és 255 közötti előjel nélküli 8 bites egész számértékek gyűjteménye, amelyek megfelelnek a pixel szürkeárnyalatos értékének, ahol a \"0\" fekete, a \"255\" fehér, az összes többi érték pedig a kettő között van:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_qTDCHgdZJF",
        "outputId": "ed17094f-cc07-43ea-863f-abc613ff1c7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2nsUuYwdZJF",
        "outputId": "273314b3-b8dd-43ea-ee5c-2e5d11d8c098"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvZhJ-LpdZJF",
        "outputId": "da1eaa4f-62d5-478d-e2e0-1e931a3ee924"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy3Bqi9VdZJF",
        "outputId": "514c0bc0-7056-4a9d-c80d-ca1e380cbe8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzv6GY4JdZJG"
      },
      "source": [
        "A [Matplotlib](https://matplotlib.org/) segítségével megjeleníthetjük az egyik ilyen szürkeárnyalatos képet az adathalmazunkban:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ESdHIIkdZJG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = x_train[0]\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_3Eu6ccdZJG"
      },
      "source": [
        "Így most már láthatjuk, hogy ez egy 28x28 pixeles kép egy 5-ösről. Vagy inkább egy 3-asról van szó? A választ az `y_train` adatban találjuk, amely az adatok helyes címkéit tartalmazza. Vessünk rá egy pillantást:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHa1_IPAdZJG"
      },
      "outputs": [],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Td4uZ6adZJG"
      },
      "source": [
        "## Az adatok előkészítése a tanításhoz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04p2n3gmdZJH"
      },
      "source": [
        "A mélytanulásban gyakori, hogy az adatokat át kell alakítani, hogy a képzéshez ideális állapotba kerüljenek. Ennél a konkrét képosztályozási problémánál 3 feladatot kell elvégeznünk az adatokkal a képzés előkészítése során:\n",
        "1. Laposítsuk a képadatokat, hogy egyszerűsítsük a kép bemenetét a modellbe.\n",
        "2. Normalizáljuk a képadatokat, hogy a modell számára könnyebbé tegyük a kép bemeneti értékeinek feldolgozását.\n",
        "3. A címkék kategorizálása, hogy a modell számára könnyebb legyen a címkeértékekkel dolgozni."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RP5J_S1dZJH"
      },
      "source": [
        "### A képadatok kiegyenlítése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltvVY7tidZJH"
      },
      "source": [
        "Bár lehetséges, hogy egy mély tanulási modell elfogad egy 2 dimenziós képet (esetünkben 28x28 pixel), mi leegyszerűsítjük a dolgokat, és [átformáljuk](https://www.tensorflow.org/api_docs/python/tf/reshape) minden egyes képet egyetlen 784 folyamatos pixelből álló tömbre (megjegyzés: 28x28 = 784). Ezt nevezik a kép ellapításának is.\n",
        "\n",
        "Itt ezt a `reshape` segédmetódus segítségével valósítjuk meg:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQNCl72CdZJH"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_valid = x_valid.reshape(10000, 784)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZcrCTVodZJH"
      },
      "source": [
        "Megerősíthetjük, hogy a képadatok átformálódtak, és most 1D-s tömbök gyűjteménye, amelyek egyenként 784 pixelértéket tartalmaznak:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_aZ4fpldZJI"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Dp9QpEdZJI"
      },
      "outputs": [],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGJ6y4nEdZJI"
      },
      "source": [
        "### A képadatok normalizálása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghcrhsrvdZJI"
      },
      "source": [
        "A mélytanulási modellek jobban tudnak bánni a 0 és 1 közötti lebegőpontos számokkal (erről a témáról később). Az egész számok 0 és 1 közötti lebegőpontos értékekké való átalakítását [normalizálásnak] (https://developers.google.com/machine-learning/glossary#normalization) nevezik, és egy egyszerű megközelítés, amit itt az adatok normalizálására fogunk alkalmazni, az lesz, hogy az összes pixelértéket (amelyek, ha emlékszik, 0 és 255 között vannak) 255-tel osztjuk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IklzZ88dZJI"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zRiE2LedZJI"
      },
      "source": [
        "Most láthatjuk, hogy az értékek mind lebegőpontos értékek a \"0.0\" és \"1.0\" értékek között:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lHi_0aKdZJJ"
      },
      "outputs": [],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uH9VJTjdZJJ"
      },
      "outputs": [],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP_Z7lJudZJJ"
      },
      "outputs": [],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_ElDovmdZJJ"
      },
      "source": [
        "### Kategorikus kódolás"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgN7FDaJdZJJ"
      },
      "source": [
        "Gondoljunk bele egy pillanatra, ha azt kérdeznénk, hogy mi a 7 - 2? Ha azt mondjuk, hogy a válasz 4, az közelebb áll ahhoz, mintha azt mondanánk, hogy a válasz 9. Azonban ennél a képosztályozási problémánál nem akarjuk, hogy a neurális hálózat megtanulja ezt a fajta érvelést: csak azt akarjuk, hogy válassza ki a helyes kategóriát, és értse meg, hogy ha van egy képünk az 5-ös számról, akkor a 4-es kitalálása ugyanolyan rossz, mint a 9-es kitalálása.\n",
        "\n",
        "A jelenlegi helyzetben a képek címkéi 0 és 9 közötti egész számok. Mivel ezek az értékek egy számtartományt képviselnek, a modell megpróbálhat következtetéseket levonni a teljesítményéről az alapján, hogy milyen közel van a helyes számkategóriához, amit kitalál.\n",
        "\n",
        "Ezért az adatainkkal valami olyasmit fogunk csinálni, amit kategorikus kódolásnak nevezünk. Ez a fajta átalakítás úgy módosítja az adatokat, hogy minden egyes érték az összes lehetséges kategória gyűjteménye legyen, azzal a tényleges kategóriával, amelyet az adott érték igaznak állít be.\n",
        "\n",
        "Egyszerű példaként gondoljunk arra, hogy 3 kategóriánk van: piros, kék és zöld. Egy adott szín esetében e kategóriák közül 2 hamis lenne, a másik pedig igaz:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12PNuE-YdZJK"
      },
      "source": [
        "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
        "|------------|---------|----------|----------|\n",
        "|Red|True|False|False|\n",
        "|Green|False|False|True|\n",
        "|Blue|False|True|False|\n",
        "|Green|False|False|True|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7gPKwR-dZJK"
      },
      "source": [
        "Ahelyett, hogy az \"Igaz\" vagy \"Hamis\" kifejezést használnánk, ugyanezt binárisan is ábrázolhatnánk, 0 vagy 1 értékkel:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdsY7DvkdZJK"
      },
      "source": [
        "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
        "|------------|---------|----------|----------|\n",
        "|Red|1|0|0|\n",
        "|Green|0|0|1|\n",
        "|Blue|0|1|0|\n",
        "|Green|0|0|1|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AMdXpRmdZJK"
      },
      "source": [
        "Ez a kategorikus kódolás lényege, hogy a kategorikus címkékként értelmezendő értékeket olyan reprezentációvá alakítjuk át, amely a modell számára egyértelművé teszi kategorikus jellegüket. Ha tehát ezeket az értékeket használnánk a képzéshez, akkor átalakítanánk..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ82E9gqdZJK"
      },
      "source": [
        "```python\n",
        "values = ['red, green, blue, green']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t5jfWTtdZJK"
      },
      "source": [
        "... amit egy neurális hálózat nagyon nehezen tudna értelmezni, ehelyett:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt7ffG39dZJL"
      },
      "source": [
        "```python\n",
        "values = [\n",
        "    [1, 0, 0],\n",
        "    [0, 0, 1],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1]\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3RtF_OKdZJL"
      },
      "source": [
        "### A címkék kategorikus kódolása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAWq0EendZJL"
      },
      "source": [
        "A Keras biztosít egy segédprogramot a [kategorikus értékek kódolása](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) számára, és itt ezt használjuk a kategorikus kódolás elvégzésére mind a képzési, mind a validálási címkék esetében:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mm3GfdxHdZJL"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "num_categories = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4u9EJIJdZJL"
      },
      "source": [
        "Itt van a képzési címkék első 10 értéke, amelyeket most már kategorikusan kódoltunk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9bY0bqLdZJM"
      },
      "outputs": [],
      "source": [
        "y_train[0:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsEhnjuBdZJM"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVeeddBgdZJM"
      },
      "source": [
        "With the data prepared for training, it is now time to create the model that we will train with the data. This first basic model will be made up of several *layers* and will be comprised of 3 main parts:\n",
        "\n",
        "1. An input layer, which will receive data in some expected format\n",
        "2. Several [hidden layers](https://developers.google.com/machine-learning/glossary#hidden-layer), each comprised of many *neurons*. Each [neuron](https://developers.google.com/machine-learning/glossary#neuron) will have the ability to affect the network's guess with its *weights*, which are values that will be updated over many iterations as the network gets feedback on its performance and learns\n",
        "3. An output layer, which will depict the network's guess for a given image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6tJwcredZJM"
      },
      "source": [
        "### Instantiating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtZYtvibdZJM"
      },
      "source": [
        "To begin, we will use Keras's [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class to instantiate an instance of a model that will have a series of layers that data will pass through in sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pKBprTndZJN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcqQVwzVdZJN"
      },
      "source": [
        "### Creating the Input Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX0ZxDn0dZJN"
      },
      "source": [
        "Next, we will add the input layer. This layer will be *densely connected*, meaning that each neuron in it, and its weights, will affect every neuron in the next layer. To do this with Keras, we use Keras's [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZB39FSedZJN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CV7sIctdZJN"
      },
      "source": [
        "The `units` argument specifies the number of neurons in the layer. We are going to use `512` which we have chosen from experimentation. Choosing the correct number of neurons is what puts the \"science\" in \"data science\" as it is a matter of capturing the statistical complexity of the dataset. Try playing around with this value later to see how it affects training and to start developing a sense for what this number means.\n",
        "\n",
        "We will learn more about activation functions later, but for now, we will use the `relu` activation function, which in short, will help our network to learn how to make more sophisticated guesses about data than if it were required to make guesses based on some strictly linear function.\n",
        "\n",
        "The `input_shape` value specifies the shape of the incoming data which in our situation is a 1D array of 784 values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zTmOLYzdZJO"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWottj66dZJO"
      },
      "source": [
        "### Creating the Hidden Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAcvEqJGdZJO"
      },
      "source": [
        "Now we will add an additional densely connected layer. Again, much more will be said about these later, but for now know that these layers give the network more parameters to contribute towards its guesses, and therefore, more subtle opportunities for accurate learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV0lULrZdZJO"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 512, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ahozAHXdZJO"
      },
      "source": [
        "### Creating the Output Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixR93qX2dZJO"
      },
      "source": [
        "Finally, we will add an output layer. This layer uses the activation function `softmax` which will result in each of the layer's values being a probability between 0 and 1 and will result in all the outputs of the layer adding to 1. In this case, since the network is to make a guess about a single image belonging to 1 of 10 possible categories, there will be 10 outputs. Each output gives the model's guess (a probability) that the image belongs to that specific class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maLY7qN3dZJP"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl-MG_DZdZJP"
      },
      "source": [
        "### Summarizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqGd3kkVdZJP"
      },
      "source": [
        "Keras provides the model instance method [summary](https://www.tensorflow.org/api_docs/python/tf/summary) which will print a readable summary of a model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JfwgWWtdZJP"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tCrSjLvdZJP"
      },
      "source": [
        "Note the number of trainable parameters. Each of these can be adjusted during training and will contribute towards the trained model's guesses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HD26OCWdZJP"
      },
      "source": [
        "### Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh2nxR4-dZJQ"
      },
      "source": [
        "Again, more details are to follow, but the final step we need to do before we can actually train our model with data is to [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) it. Here we specify a [loss function](https://developers.google.com/machine-learning/glossary#loss) which will be used for the model to understand how well it is performing during training. We also specify that we would like to track `accuracy` while the model trains:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQcNe4JadZJQ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0F8BjIsdZJQ"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcOhHjU8dZJQ"
      },
      "source": [
        "Now that we have prepared training and validation data, and a model, it's time to train our model with our training data, and verify it with its validation data.\n",
        "\n",
        "\"Training a model with data\" is often also called \"fitting a model to data.\" Put this latter way, it highlights that the shape of the model changes over time to more accurately understand the data that it is being given.\n",
        "\n",
        "When fitting (training) a model with Keras, we use the model's [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method. It expects the following arguments:\n",
        "\n",
        "* The training data\n",
        "* The labels for the training data\n",
        "* The number of times it should train on the entire training dataset (called an *epoch*)\n",
        "* The validation or test data, and its labels\n",
        "\n",
        "Run the cell below to train the model. We will discuss its output after the training completes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60Lr6RHTdZJQ"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovi1fdGadZJR"
      },
      "source": [
        "### Observing Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqHM_uRadZJR"
      },
      "source": [
        "For each of the 5 epochs, notice the `accuracy` and `val_accuracy` scores. `accuracy` states how well the model did for the epoch on all the training data. `val_accuracy` states how well the model did on the validation data, which if you recall, was not used at all for training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EktMzcREdZJR"
      },
      "source": [
        "The model did quite well! The accuracy quickly reached close to 100%, as did the validation accuracy. We now have a model that can be used to accurately detect and classify hand-written images.\n",
        "\n",
        "The next step would be to use this model to classify new not-yet-seen handwritten images. This is called [inference](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/). We'll explore the process of inference in a later exercise. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntSXtK8-dZJR"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_JaX6aBdZJR"
      },
      "source": [
        "It's worth taking a moment to appreciate what we've done here. Historically, the expert systems that were built to do this kind of task were extremely complicated, and people spent their careers building them (check out the references on the [official MNIST page](http://yann.lecun.com/exdb/mnist/) and the years milestones were reached).\n",
        "\n",
        "MNIST is not only useful for its historical influence on Computer Vision, but it's also a great [benchmark](http://www.cs.toronto.edu/~serailhydra/publications/tbd-iiswc18.pdf) and debugging tool. Having trouble getting a fancy new machine learning architecture working? Check it against MNIST. If it can't learn on this dataset, chances are it won't learn on more complicated images and datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkicyn82dZJS"
      },
      "source": [
        "## Clear the Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA04Oi2XdZJS"
      },
      "source": [
        "Before moving on, please execute the following cell to clear up the GPU memory. This is required to move on to the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eIPR1fIdZJS"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S3o8Hc1dZJS"
      },
      "source": [
        "## Next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5aYNTFCdZJS"
      },
      "source": [
        "In this section you learned how to build and train a simple neural network for image classification. In the next section, you will be asked to build your own neural network and perform data preparation to solve a different image classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fQaCm7idZJT"
      },
      "source": [
        "## ☆ Bonus Exercise ☆\n",
        "\n",
        "Have time to spare? In the next section, we will talk about how we arrived at some of the numbers above, but we can try imagining what it was like to be a researcher developing the techniques commonly used today.\n",
        "\n",
        "Ultimately, each neuron is trying to fit a line to some data. Below, we have some datapoints and a randomly drawn line using the equation [y = mx + b](https://www.mathsisfun.com/equation_of_line.html).\n",
        "\n",
        "Try changing the `m` and the `b` in order to find the lowest possible loss. How did you find the best line? Can you make a program to follow your strategy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9dt-whOdZJT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.polynomial.polynomial import polyfit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "m = -2  # -2 to start, change me please\n",
        "b = 40  # 40 to start, change me please\n",
        "\n",
        "# Sample data\n",
        "x = np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
        "y = np.array([10, 20, 25, 30, 40, 45, 40, 50, 60, 55])\n",
        "y_hat = x * m + b\n",
        "\n",
        "plt.plot(x, y, '.')\n",
        "plt.plot(x, y_hat, '-')\n",
        "plt.show()\n",
        "\n",
        "print(\"Loss:\", np.sum((y - y_hat)**2)/len(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFatOUP_dZJT"
      },
      "source": [
        "Have an idea? Excellent! Please shut down the kernel before moving on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61fLXT6zdZJT"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "01_mnist_hu.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}